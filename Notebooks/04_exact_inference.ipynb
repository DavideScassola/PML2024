{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b37f87",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavideScassola/PML2024/blob/main/Notebooks/04_exact_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact inference with Belief Propagation\n",
    "\n",
    "This notebook is inspired from [Jessica Stringham's work](https://jessicastringham.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform inference through the sum-product message passing, or belief propagation, on tree-like factor graphs (without any loop). We work only with discrete distributions and without using ad-hoc libraries, to better understand the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distributions\n",
    "\n",
    "First of all, we need to represent a discrete probability distribution and check that it is normalized.\n",
    "For example, we can represent a discrete conditional distribution $p(v_1 | h_1)$ with a 2D array, as:\n",
    "\n",
    "|   | $h_1=a$ | $h_1=b$ | $h_1=c$|\n",
    "|---|-----|-----|----|\n",
    "| $v_1=0$ | 0.4  | 0.8  | 0.9|\n",
    "| $v_1=1$ | 0.6 | 0.2  | 0.1|\n",
    "\n",
    "We can build a class for the distributions containing the arrays and the labels of the axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution():\n",
    "    \"\"\"\"\n",
    "    Discrete probability distributions, expressed using labeled arrays\n",
    "    probs: array of probability values\n",
    "    axes_labels: list of axes names\n",
    "    \"\"\"\n",
    "    def __init__(self, probs, axes_labels):\n",
    "        self.probs = probs\n",
    "        self.axes_labels = axes_labels\n",
    "\n",
    "    def get_axes(self):\n",
    "        #returns a dictionary with axes names and the corresponding coordinates\n",
    "        return {name: axis for axis, name in enumerate(self.axes_labels)}\n",
    "    \n",
    "    def get_other_axes_from(self, axis_label):\n",
    "        #returns a tuple containing all the axes except from axis_label\n",
    "        return tuple(axis for axis, name in enumerate(self.axes_labels) if name != axis_label)\n",
    "    \n",
    "    def is_valid_conditional(self, variable_name):\n",
    "        #variable_name is the name of the variable for which we are computing the distribution, e.g. in p(y|x) it is 'y'\n",
    "        return np.all(np.isclose(np.sum(self.probs, axis=self.get_axes()[variable_name]), 1.0))\n",
    "    \n",
    "    def is_valid_joint(self):\n",
    "        return np.all(np.isclose(np.sum(self.probs), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is p(v1|h1) a valid conditional distribution?  True\n",
      "Is p(v1|h1) a valid joint distribution?  False\n",
      "Is p(h1) a valid conditional distribution?  True\n",
      "Is p(h1) a valid joint distribution?  True\n",
      "Is p(v1|h1, h2) a valid conditional distribution?  True\n",
      "Is p(v1|h1, h2) a valid joint distribution?  False\n"
     ]
    }
   ],
   "source": [
    "#Let's see the previous distribution:\n",
    "\n",
    "p_v1_given_h1 = Distribution(np.array([[0.4, 0.8, 0.9], [0.6, 0.2, 0.1]]), ['v1', 'h1'])\n",
    "\n",
    "print('Is p(v1|h1) a valid conditional distribution? ', p_v1_given_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1) a valid joint distribution? ', p_v1_given_h1.is_valid_joint())\n",
    "\n",
    "#Consider also a joint distribution and a conditional distribution with more than one 'given' variables\n",
    "\n",
    "p_h1 = Distribution(np.array([0.6, 0.3, 0.1]), ['h1'])\n",
    "\n",
    "print('Is p(h1) a valid conditional distribution? ', p_h1.is_valid_conditional('h1'))\n",
    "print('Is p(h1) a valid joint distribution? ', p_h1.is_valid_joint())\n",
    "\n",
    "p_v1_given_h0_h1 = Distribution(np.array([[[0.9, 0.2, 0.7], [0.3, 0.2, 0.5]],[[0.1, 0.8, 0.3], [0.7, 0.8, 0.5]]]), ['v1', 'h0', 'h1'])\n",
    "print('Is p(v1|h1, h2) a valid conditional distribution? ', p_v1_given_h0_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1, h2) a valid joint distribution? ', p_v1_given_h0_h1.is_valid_joint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to allow multiplications between distributions like $p(v_1|h_1,...,h_n) p(h_i)$, where p(hi) is a 1D array.\n",
    "To do it, we can exploit broadcasting. But first, we need to reshape $p(h_i)$ accordingly to the dimension $h_i$ of the distribution $p(v_1|h_1,...,h_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(p_v_given_h: Distribution, p_hi: Distribution) -> Distribution:\n",
    "    ''' \n",
    "    Compute the product of the distributions p(v|h1,..,hn)p(hi) where p(hi) is a 1D array\n",
    "    '''\n",
    "    #Get the axis corresponding to hi in the conditional distribution\n",
    "    axis=p_v_given_h.get_axes()[next(iter(p_hi.get_axes()))]\n",
    "    \n",
    "    # Reshape p(hi) in order to exploit broadcasting. Consider also the case in which p(hi) is a scalar.\n",
    "    dims=np.ones_like(p_v_given_h.probs.shape)\n",
    "    dims[axis] = p_v_given_h.probs.shape[axis]\n",
    "\n",
    "    if (p_hi.probs.shape != () ):\n",
    "        reshaped_p_hi = p_hi.probs.reshape(dims)\n",
    "    else:\n",
    "        reshaped_p_hi = p_hi.probs\n",
    "\n",
    "        \n",
    "    return Distribution(p_v_given_h.probs*reshaped_p_hi, p_v_given_h.axes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24 0.24 0.09]\n",
      " [0.36 0.06 0.01]]\n",
      "True\n",
      "[[[0.54 0.06 0.07]\n",
      "  [0.18 0.06 0.05]]\n",
      "\n",
      " [[0.06 0.24 0.03]\n",
      "  [0.42 0.24 0.05]]]\n"
     ]
    }
   ],
   "source": [
    "p_v1_h1 = multiply(p_v1_given_h1, p_h1)\n",
    "print(p_v1_h1.probs)\n",
    "print(p_v1_h1.is_valid_joint())\n",
    "\n",
    "p_v1_h1_given_h0 = multiply(p_v1_given_h0_h1, p_h1)\n",
    "print(p_v1_h1_given_h0.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor graphs\n",
    "\n",
    "Factor graphs are bipartite graphs, with variable nodes and factor nodes. Edges can only connect nodes of different type. Consider for example:\n",
    "\n",
    "![factor_ex](imgs/factor_example.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.neighbors = []\n",
    "\n",
    "    def is_valid_neighbor(self, neighbor):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        assert self.is_valid_neighbor(neighbor)\n",
    "        self.neighbors.append(neighbor)\n",
    "\n",
    "\n",
    "class Variable(Node):\n",
    "    def is_valid_neighbor(self, factor):\n",
    "        return isinstance(factor, Factor)  # Variables can only neighbor Factors\n",
    "\n",
    "\n",
    "class Factor(Node):\n",
    "    def is_valid_neighbor(self, variable):\n",
    "        return isinstance(variable, Variable)  # Factors can only neighbor Variables\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super(Factor, self).__init__(name)\n",
    "        self.distribution = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build some parsing methods in order to create a factor graph from a string representing the factorization of the joint probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "        \n",
    "ParsedTerm = namedtuple('ParsedTerm', [\n",
    "    'term',\n",
    "    'var_name',\n",
    "    'given',\n",
    "])\n",
    "\n",
    "\n",
    "def _parse_term(term):\n",
    "    # Given a term like (a|b,c), returns a list of variables\n",
    "    # and conditioned-on variables\n",
    "    assert term[0] == '(' and term[-1] == ')'\n",
    "    term_variables = term[1:-1]\n",
    "\n",
    "    # Handle conditionals\n",
    "    if '|' in term_variables:\n",
    "        var, given = term_variables.split('|')\n",
    "        given = given.split(',')\n",
    "    else:\n",
    "        var = term_variables\n",
    "        given = []\n",
    "\n",
    "    return var, given\n",
    "\n",
    "\n",
    "def _parse_model_string_into_terms(model_string):\n",
    "    return [\n",
    "        ParsedTerm('p' + term, *_parse_term(term))\n",
    "        for term in model_string.split('p')\n",
    "        if term\n",
    "    ]\n",
    "\n",
    "def parse_model_into_variables_and_factors(model_string):\n",
    "    # Takes in a model_string such as p(h1)p(h2∣h1)p(v1∣h1)p(v2∣h2) and returns a\n",
    "    # dictionary of variable names to variables and a list of factors.\n",
    "    \n",
    "    # Split model_string into ParsedTerms\n",
    "    parsed_terms = _parse_model_string_into_terms(model_string)\n",
    "    \n",
    "    # First, extract all of the variables from the model_string (h1, h2, v1, v2). \n",
    "    # These each will be a new Variable that are referenced from Factors below.\n",
    "    variables = {}\n",
    "    for parsed_term in parsed_terms:\n",
    "        # if the variable name wasn't seen yet, add it to the variables dict\n",
    "        if parsed_term.var_name not in variables:\n",
    "            variables[parsed_term.var_name] = Variable(parsed_term.var_name)\n",
    "\n",
    "    # Now extract factors from the model. Each term (e.g. \"p(v1|h1)\") corresponds to \n",
    "    # a factor. \n",
    "    # Then find all variables in this term (\"v1\", \"h1\") and add the corresponding Variables\n",
    "    # as neighbors to the new Factor, and this Factor to the Variables' neighbors.\n",
    "    factors = []\n",
    "    for parsed_term in parsed_terms:\n",
    "        # This factor will be neighbors with all \"variables\" (left-hand side variables) and given variables\n",
    "        new_factor = Factor(parsed_term.term)\n",
    "        all_var_names = [parsed_term.var_name] + parsed_term.given\n",
    "        for var_name in all_var_names:\n",
    "            new_factor.add_neighbor(variables[var_name])\n",
    "            variables[var_name].add_neighbor(new_factor)\n",
    "        factors.append(new_factor)\n",
    "\n",
    "    return factors, variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine factor nodes and variable nodes to create a factor graph and add a distribution to each factor node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGM(object):\n",
    "    def __init__(self, factors, variables):\n",
    "        self._factors = factors\n",
    "        self._variables = variables\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, model_string):\n",
    "        factors, variables = parse_model_into_variables_and_factors(model_string)\n",
    "        return PGM(factors, variables)\n",
    "\n",
    "    def set_distributions(self, distributions):\n",
    "        var_dims = {}\n",
    "        for factor in self._factors:\n",
    "            factor_data = distributions[factor.name]\n",
    "\n",
    "            if set(factor_data.axes_labels) != set(v.name for v in factor.neighbors):\n",
    "                missing_axes = set(v.name for v in factor.neighbors) - set(distributions[factor.name].axes_labels)\n",
    "                raise ValueError(\"data[{}] is missing axes: {}\".format(factor.name, missing_axes))\n",
    "                \n",
    "            for var_name, dim in zip(factor_data.axes_labels, factor_data.probs.shape):\n",
    "                if var_name not in var_dims:\n",
    "                    var_dims[var_name] = dim\n",
    "    \n",
    "                if var_dims[var_name] != dim:\n",
    "                    raise ValueError(\"data[{}] axes is wrong size, {}. Expected {}\".format(factor.name, dim, var_dims[var_name]))            \n",
    "                    \n",
    "            factor.distribution = distributions[factor.name]\n",
    "            \n",
    "    def variable_from_name(self, var_name):\n",
    "        return self._variables[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, in the previous example, we can write the marginal as a combination of sums and products:\n",
    "\n",
    "$$p(x_5) = \\sum_{x_1, x_2, x_3, x_4}p(x_1, x_2, x_3, x_4, x_5) =\\\\ = \\sum_{x_3, x_4}f_3(x_3,x_4,x_5)\\bigg[\\sum_{x_1}f_1(x_1, x_3)\\bigg]\\bigg[\\sum_{x_2}f_2(x_2, x_3)\\bigg]$$\n",
    "\n",
    "and interpret them as messages flowing from factors to variables (including a summation) or from variables to factors (via multiplication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        self.messages = {}\n",
    "        \n",
    "    def _variable_to_factor_messages(self, variable: Variable, factor: Factor):\n",
    "        # Take the product over all incoming factors into this variable except the variable\n",
    "        incoming_messages = [\n",
    "            self.factor_to_variable_message(neighbor_factor, variable)\n",
    "            for neighbor_factor in variable.neighbors\n",
    "            if neighbor_factor.name != factor.name\n",
    "        ]\n",
    "\n",
    "        # If there are no incoming messages, this is 1 (BASE CASE)\n",
    "        return np.prod(incoming_messages, axis=0)\n",
    "    \n",
    "    def _factor_to_variable_messages(self, factor, variable: Variable):\n",
    "        #reinstantiate to obtain a deep copy\n",
    "        factor_dist = Distribution(factor.distribution.probs, factor.distribution.axes_labels)\n",
    "\n",
    "        for neighbor_variable in factor.neighbors:\n",
    "            if neighbor_variable.name == variable.name:\n",
    "                continue\n",
    "            #Retrieve the incoming message and multiply the conditional distribution of the factor with the message\n",
    "            incoming_message = self.variable_to_factor_messages(neighbor_variable, factor)\n",
    "            factor_dist = multiply(factor_dist, Distribution(incoming_message, [neighbor_variable.name]))\n",
    "\n",
    "        # Sum over the axes that aren't `variable`\n",
    "        factor_dist = factor_dist.probs\n",
    "        other_axes = factor.distribution.get_other_axes_from(variable.name)\n",
    "        return np.squeeze(np.sum(factor_dist, axis=other_axes))\n",
    "    \n",
    "    \n",
    "    def marginal(self, variable):\n",
    "        # p(variable) is proportional to the product of incoming messages to variable.\n",
    "        unnorm_p = np.prod([\n",
    "            self.factor_to_variable_message(neighbor_factor, variable)\n",
    "            for neighbor_factor in variable.neighbors\n",
    "        ], axis=0)\n",
    "\n",
    "        # At this point, we can normalize this distribution\n",
    "        return unnorm_p/np.sum(unnorm_p)\n",
    "    \n",
    "    def variable_to_factor_messages(self, variable, factor):\n",
    "        message_name = (variable.name, factor.name)\n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._variable_to_factor_messages(variable, factor)\n",
    "        return self.messages[message_name]\n",
    "        \n",
    "    def factor_to_variable_message(self, factor, variable):\n",
    "        message_name = (factor.name, variable.name)\n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._factor_to_variable_messages(factor, variable)\n",
    "        return self.messages[message_name]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to build the following factor graph:\n",
    "\n",
    "![factor1](imgs/factor2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_h1 = Distribution(np.array([[0.2], [0.8]]), ['h1'])\n",
    "p_h2_given_h1 = Distribution(np.array([[0.5, 0.2], [0.5, 0.8]]), ['h2', 'h1'])\n",
    "p_v1_given_h1 = Distribution(np.array([[0.6, 0.1], [0.4, 0.9]]), ['v1', 'h1'])\n",
    "p_v2_given_h2 = Distribution(p_v1_given_h1.probs, ['v2', 'h2'])\n",
    "\n",
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the marginal distribution $p(v_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23, 0.77])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})\n",
    "\n",
    "m = Messages()\n",
    "m.marginal(pgm.variable_from_name('v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('p(h1)', 'h1'): array([0.2, 0.8]),\n",
       " ('v1', 'p(v1|h1)'): 1.0,\n",
       " ('p(v1|h1)', 'h1'): array([1., 1.]),\n",
       " ('h1', 'p(h2|h1)'): array([0.2, 0.8]),\n",
       " ('p(h2|h1)', 'h2'): array([0.26, 0.74]),\n",
       " ('h2', 'p(v2|h2)'): array([0.26, 0.74]),\n",
       " ('p(v2|h2)', 'v2'): array([0.23, 0.77])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.marginal(pgm.variable_from_name('v1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "(From Bayesian Reasoning and Machine Learning, David Barber) You live in a house with three rooms, labelled 1, 2, 3. There is a door between rooms 1 and 2 and another between rooms 2 and 3. One cannot directly pass between rooms 1 and 3 in one time-step. An annoying fly is buzzing from one room to another and there is some smelly cheese in room 1 which seems to attract the fly more. Using $x_t$ for which room the fly is in at time t, with $dom(x_t) = {1,2,3}$, the movement of the fly can be described by a transition:\n",
    "$p(x_{t+1} = i|x_t = j) = M_{ij}$\n",
    "\n",
    "where M is a transition matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.5 & 0 \\\\\n",
    "0.3 & 0.3 & 0.5 \\\\\n",
    "0 & 0.2 & 0.5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Given that the fly is in room 1 at time 1, what is the probability of room occupancy at time t = 5? Assume a Markov chain which is defined by the joint distribution\n",
    "\n",
    "$p(x_1, . . . , x_T ) = p(x_1) \\prod p(x_{t+1}|x_t)$\n",
    "\n",
    "We are asked to compute $p(x_5|x_1 = 1)$ which is given by\n",
    "$\\sum p(x_5|x_4)p(x_4|x_3)p(x_3|x_2)p(x_2|x_1 = 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('p(x1)', 'x1'): array([1, 0, 0]),\n",
       " ('x1', 'p(x2|x1)'): array([1, 0, 0]),\n",
       " ('p(x2|x1)', 'x2'): array([0.7, 0.3, 0. ]),\n",
       " ('x2', 'p(x3|x2)'): array([0.7, 0.3, 0. ]),\n",
       " ('p(x3|x2)', 'x3'): array([0.64, 0.3 , 0.06]),\n",
       " ('x3', 'p(x4|x3)'): array([0.64, 0.3 , 0.06]),\n",
       " ('p(x4|x3)', 'x4'): array([0.598, 0.312, 0.09 ]),\n",
       " ('x4', 'p(x5|x4)'): array([0.598, 0.312, 0.09 ]),\n",
       " ('p(x5|x4)', 'x5'): array([0.5746, 0.318 , 0.1074])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm = PGM.from_string(\"p(x5|x4)p(x4|x3)p(x3|x2)p(x2|x1)p(x1)\")\n",
    "\n",
    "p_x5_given_x4 = Distribution(np.array([[0.7, 0.5, 0], [0.3, 0.3, 0.5], [0, 0.2, 0.5]]), ['x5', 'x4'])\n",
    "p_x4_given_x3 = Distribution(p_x5_given_x4.probs, ['x4', 'x3'])\n",
    "p_x3_given_x2 = Distribution(p_x5_given_x4.probs, ['x3', 'x2'])\n",
    "p_x2_given_x1 = Distribution(p_x5_given_x4.probs, ['x2', 'x1'])\n",
    "p_x1 = Distribution(np.array([1, 0, 0]), ['x1'])\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(x5|x4)\": p_x5_given_x4,\n",
    "    \"p(x4|x3)\": p_x4_given_x3,\n",
    "    \"p(x3|x2)\": p_x3_given_x2,\n",
    "    \"p(x2|x1)\": p_x2_given_x1,\n",
    "    \"p(x1)\": p_x1,\n",
    "})\n",
    "\n",
    "m2 = Messages()\n",
    "m2.marginal(pgm.variable_from_name('x5'))\n",
    "\n",
    "m2.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Hidden Markov Models\n",
    "\n",
    "Imagine you're trying to guess someone's mood without directly asking them or using brain electrodes. Instead, you observe their facial expressions, whether they're smiling or frowning, to make an educated guess.\n",
    "\n",
    "We assume moods can be categorized into two states: good and bad. When you meet someone for the first time, there's a 70% chance they're in a good mood and a 30% chance they're in a bad mood.\n",
    "\n",
    "If someone is in a good mood, there's an 80% chance they'll stay in a good mood and a 20% chance they'll switch to a bad mood over time. The same probabilities of switching the mood apply if they start in a bad mood.\n",
    "\n",
    "Lastly, when someone is in a good mood, they're 90% likely to smile and 10% likely to frown. Conversely, if they're in a bad mood, they have a 10% chance of smiling and a 90% chance of frowning.\n",
    "\n",
    "The transitions are summarized in the following graph.\n",
    "\n",
    "Your task is to use these probabilities to figure out the first and second hidden mood states (the probability that the first mood is good/bad and the probability that the second mood is good/bad) based on the observable facial expressions you see (imagine you see the sequence [smiling, frowning]).\n",
    "\n",
    "![factor1](imgs/mood.png)\n",
    "(image by Y. Natsume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
