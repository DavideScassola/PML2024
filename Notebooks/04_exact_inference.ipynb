{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b37f87",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavideScassola/PML2024/blob/main/Notebooks/04_exact_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact inference with Belief Propagation\n",
    "\n",
    "This notebook is inspired from [Jessica Stringham's work](https://jessicastringham.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform inference through the sum-product message passing, or belief propagation, on tree-like factor graphs (without any loop). We work only with discrete distributions and without using ad-hoc libraries, to better understand the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distributions\n",
    "\n",
    "First of all, we need to represent a discrete probability distribution and check that it is normalized.\n",
    "For example, we can represent a discrete conditional distribution $p(v_1 | h_1)$ with a 2D array, as:\n",
    "\n",
    "|   | $h_1=a$ | $h_1=b$ | $h_1=c$|\n",
    "|---|-----|-----|----|\n",
    "| $v_1=0$ | 0.4  | 0.8  | 0.9|\n",
    "| $v_1=1$ | 0.6 | 0.2  | 0.1|\n",
    "\n",
    "We can build a class for the distributions containing the arrays and the labels of the axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution():\n",
    "    \"\"\"\"\n",
    "    Discrete probability distributions, expressed using labeled arrays\n",
    "    probs: array of probability values\n",
    "    axes_labels: list of axes names\n",
    "    \"\"\"\n",
    "    def __init__(self, probs, axes_labels):\n",
    "        self.probs = probs\n",
    "        self.axes_labels = axes_labels\n",
    "\n",
    "    def get_axes(self):\n",
    "        #returns a dictionary with axes names and the corresponding coordinates\n",
    "        return {name: axis for axis, name in enumerate(self.axes_labels)}\n",
    "    \n",
    "    def get_other_axes_from(self, axis_label):\n",
    "        #returns a tuple containing all the axes except from axis_label\n",
    "        return tuple(axis for axis, name in enumerate(self.axes_labels) if name != axis_label)\n",
    "    \n",
    "    def is_valid_conditional(self, variable_name):\n",
    "        #variable_name is the name of the variable for which we are computing the distribution, e.g. in p(y|x) it is 'y'\n",
    "        return np.all(np.isclose(np.sum(self.probs, axis=self.get_axes()[variable_name]), 1.0))\n",
    "    \n",
    "    def is_valid_joint(self):\n",
    "        return np.all(np.isclose(np.sum(self.probs), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is p(v1|h1) a valid conditional distribution?  True\n",
      "Is p(v1|h1) a valid joint distribution?  False\n",
      "Is p(h1) a valid conditional distribution?  True\n",
      "Is p(h1) a valid joint distribution?  True\n",
      "Is p(v1|h1, h2) a valid conditional distribution?  True\n",
      "Is p(v1|h1, h2) a valid joint distribution?  False\n"
     ]
    }
   ],
   "source": [
    "#Let's see the previous distribution:\n",
    "\n",
    "p_v1_given_h1 = Distribution(np.array([[0.4, 0.8, 0.9], [0.6, 0.2, 0.1]]), ['v1', 'h1'])\n",
    "\n",
    "print('Is p(v1|h1) a valid conditional distribution? ', p_v1_given_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1) a valid joint distribution? ', p_v1_given_h1.is_valid_joint())\n",
    "\n",
    "#Consider also a joint distribution and a conditional distribution with more than one 'given' variables\n",
    "\n",
    "p_h1 = Distribution(np.array([0.6, 0.3, 0.1]), ['h1'])\n",
    "\n",
    "print('Is p(h1) a valid conditional distribution? ', p_h1.is_valid_conditional('h1'))\n",
    "print('Is p(h1) a valid joint distribution? ', p_h1.is_valid_joint())\n",
    "\n",
    "p_v1_given_h0_h1 = Distribution(np.array([[[0.9, 0.2, 0.7], [0.3, 0.2, 0.5]],[[0.1, 0.8, 0.3], [0.7, 0.8, 0.5]]]), ['v1', 'h0', 'h1'])\n",
    "print('Is p(v1|h1, h2) a valid conditional distribution? ', p_v1_given_h0_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1, h2) a valid joint distribution? ', p_v1_given_h0_h1.is_valid_joint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to allow multiplications between distributions like $p(v_1|h_1,...,h_n) p(h_i)$, where p(hi) is a 1D array.\n",
    "To do it, we can exploit broadcasting. But first, we need to reshape $p(h_i)$ accordingly to the dimension $h_i$ of the distribution $p(v_1|h_1,...,h_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(p_v_given_h: Distribution, p_hi: Distribution) -> Distribution:\n",
    "    ''' \n",
    "    Compute the product of the distributions p(v|h1,..,hn)p(hi) where p(hi) is a 1D array\n",
    "    '''\n",
    "    #Get the axis corresponding to hi in the conditional distribution\n",
    "    axis=p_v_given_h.get_axes()[next(iter(p_hi.get_axes()))]\n",
    "    \n",
    "    # Reshape p(hi) in order to exploit broadcasting. Consider also the case in which p(hi) is a scalar.\n",
    "    # TODO: ...\n",
    "\n",
    "        \n",
    "    return Distribution(p_v_given_h.probs*reshaped_p_hi, p_v_given_h.axes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24 0.24 0.09]\n",
      " [0.36 0.06 0.01]]\n",
      "True\n",
      "[[[0.54 0.06 0.07]\n",
      "  [0.18 0.06 0.05]]\n",
      "\n",
      " [[0.06 0.24 0.03]\n",
      "  [0.42 0.24 0.05]]]\n"
     ]
    }
   ],
   "source": [
    "p_v1_h1 = multiply(p_v1_given_h1, p_h1)\n",
    "print(p_v1_h1.probs)\n",
    "print(p_v1_h1.is_valid_joint())\n",
    "\n",
    "p_v1_h1_given_h0 = multiply(p_v1_given_h0_h1, p_h1)\n",
    "print(p_v1_h1_given_h0.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor graphs\n",
    "\n",
    "Factor graphs are bipartite graphs, with variable nodes and factor nodes. Edges can only connect nodes of different type. Consider for example:\n",
    "\n",
    "![factor_ex](imgs/factor_example.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.neighbors = []\n",
    "\n",
    "    def is_valid_neighbor(self, neighbor):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        assert self.is_valid_neighbor(neighbor)\n",
    "        self.neighbors.append(neighbor)\n",
    "\n",
    "\n",
    "class Variable(Node):\n",
    "    def is_valid_neighbor(self, factor):\n",
    "        return isinstance(factor, Factor)  # Variables can only neighbor Factors\n",
    "\n",
    "\n",
    "class Factor(Node):\n",
    "    def is_valid_neighbor(self, variable):\n",
    "        return isinstance(variable, Variable)  # Factors can only neighbor Variables\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super(Factor, self).__init__(name)\n",
    "        self.distribution = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build some parsing methods in order to create a factor graph from a string representing the factorization of the joint probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "        \n",
    "ParsedTerm = namedtuple('ParsedTerm', [\n",
    "    'term',\n",
    "    'var_name',\n",
    "    'given',\n",
    "])\n",
    "\n",
    "\n",
    "def _parse_term(term):\n",
    "    # Given a term like (a|b,c), returns a list of variables\n",
    "    # and conditioned-on variables\n",
    "    assert term[0] == '(' and term[-1] == ')'\n",
    "    term_variables = term[1:-1]\n",
    "\n",
    "    # Handle conditionals\n",
    "    if '|' in term_variables:\n",
    "        var, given = term_variables.split('|')\n",
    "        given = given.split(',')\n",
    "    else:\n",
    "        var = term_variables\n",
    "        given = []\n",
    "\n",
    "    return var, given\n",
    "\n",
    "\n",
    "def _parse_model_string_into_terms(model_string):\n",
    "    return [\n",
    "        ParsedTerm('p' + term, *_parse_term(term))\n",
    "        for term in model_string.split('p')\n",
    "        if term\n",
    "    ]\n",
    "\n",
    "def parse_model_into_variables_and_factors(model_string):\n",
    "    # Takes in a model_string such as p(h1)p(h2∣h1)p(v1∣h1)p(v2∣h2) and returns a\n",
    "    # dictionary of variable names to variables and a list of factors.\n",
    "    \n",
    "    # Split model_string into ParsedTerms\n",
    "    parsed_terms = _parse_model_string_into_terms(model_string)\n",
    "    \n",
    "    # First, extract all of the variables from the model_string (h1, h2, v1, v2). \n",
    "    # These each will be a new Variable that are referenced from Factors below.\n",
    "    variables = {}\n",
    "    for parsed_term in parsed_terms:\n",
    "        # if the variable name wasn't seen yet, add it to the variables dict\n",
    "        if parsed_term.var_name not in variables:\n",
    "            variables[parsed_term.var_name] = Variable(parsed_term.var_name)\n",
    "\n",
    "    # Now extract factors from the model. Each term (e.g. \"p(v1|h1)\") corresponds to \n",
    "    # a factor. \n",
    "    # Then find all variables in this term (\"v1\", \"h1\") and add the corresponding Variables\n",
    "    # as neighbors to the new Factor, and this Factor to the Variables' neighbors.\n",
    "    factors = []\n",
    "    for parsed_term in parsed_terms:\n",
    "        # This factor will be neighbors with all \"variables\" (left-hand side variables) and given variables\n",
    "        new_factor = Factor(parsed_term.term)\n",
    "        all_var_names = [parsed_term.var_name] + parsed_term.given\n",
    "        for var_name in all_var_names:\n",
    "            new_factor.add_neighbor(variables[var_name])\n",
    "            variables[var_name].add_neighbor(new_factor)\n",
    "        factors.append(new_factor)\n",
    "\n",
    "    return factors, variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine factor nodes and variable nodes to create a factor graph and add a distribution to each factor node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGM(object):\n",
    "    def __init__(self, factors, variables):\n",
    "        self._factors = factors\n",
    "        self._variables = variables\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, model_string):\n",
    "        factors, variables = parse_model_into_variables_and_factors(model_string)\n",
    "        return PGM(factors, variables)\n",
    "\n",
    "    def set_distributions(self, distributions):\n",
    "        var_dims = {}\n",
    "        for factor in self._factors:\n",
    "            factor_data = distributions[factor.name]\n",
    "\n",
    "            if set(factor_data.axes_labels) != set(v.name for v in factor.neighbors):\n",
    "                missing_axes = set(v.name for v in factor.neighbors) - set(distributions[factor.name].axes_labels)\n",
    "                raise ValueError(\"data[{}] is missing axes: {}\".format(factor.name, missing_axes))\n",
    "                \n",
    "            for var_name, dim in zip(factor_data.axes_labels, factor_data.probs.shape):\n",
    "                if var_name not in var_dims:\n",
    "                    var_dims[var_name] = dim\n",
    "    \n",
    "                if var_dims[var_name] != dim:\n",
    "                    raise ValueError(\"data[{}] axes is wrong size, {}. Expected {}\".format(factor.name, dim, var_dims[var_name]))            \n",
    "                    \n",
    "            factor.distribution = distributions[factor.name]\n",
    "            \n",
    "    def variable_from_name(self, var_name):\n",
    "        return self._variables[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, in the previous example, we can write the marginal as a combination of sums and products:\n",
    "\n",
    "$$p(x_5) = \\sum_{x_1, x_2, x_3, x_4}p(x_1, x_2, x_3, x_4, x_5) =\\\\ = \\sum_{x_3, x_4}f_3(x_3,x_4,x_5)\\bigg[\\sum_{x_1}f_1(x_1, x_3)\\bigg]\\bigg[\\sum_{x_2}f_2(x_2, x_3)\\bigg]$$\n",
    "\n",
    "and interpret them as messages flowing from factors to variables (including a summation) or from variables to factors (via multiplication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        self.messages = {}\n",
    "        \n",
    "    def _variable_to_factor_messages(self, variable: Variable, factor: Factor):\n",
    "        # Take the product over all incoming factors into this variable except the variable\n",
    "        incoming_messages = [\n",
    "            self.factor_to_variable_message(neighbor_factor, variable)\n",
    "            for neighbor_factor in variable.neighbors\n",
    "            if neighbor_factor.name != factor.name\n",
    "        ]\n",
    "\n",
    "        # If there are no incoming messages, this is 1 (BASE CASE)\n",
    "        return np.prod(incoming_messages, axis=0)\n",
    "    \n",
    "    def _factor_to_variable_messages(self, factor, variable: Variable):\n",
    "        #reinstantiate to obtain a deep copy\n",
    "        factor_dist = Distribution(factor.distribution.probs, factor.distribution.axes_labels)\n",
    "\n",
    "        for neighbor_variable in factor.neighbors:\n",
    "            if neighbor_variable.name == variable.name:\n",
    "                continue\n",
    "            #Retrieve the incoming message and multiply the conditional distribution of the factor with the message\n",
    "            # TODO: ...\n",
    "\n",
    "\n",
    "        # Sum over the axes that aren't `variable`\n",
    "        # TODO: ...\n",
    "\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def marginal(self, variable):\n",
    "        # p(variable) is proportional to the product of incoming messages to variable.\n",
    "        unnorm_p = np.prod([\n",
    "            self.factor_to_variable_message(neighbor_factor, variable)\n",
    "            for neighbor_factor in variable.neighbors\n",
    "        ], axis=0)\n",
    "\n",
    "        # At this point, we can normalize this distribution\n",
    "        return unnorm_p/np.sum(unnorm_p)\n",
    "    \n",
    "    def variable_to_factor_messages(self, variable, factor):\n",
    "        message_name = (variable.name, factor.name)\n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._variable_to_factor_messages(variable, factor)\n",
    "        return self.messages[message_name]\n",
    "        \n",
    "    def factor_to_variable_message(self, factor, variable):\n",
    "        message_name = (factor.name, variable.name)\n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._factor_to_variable_messages(factor, variable)\n",
    "        return self.messages[message_name]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to build the following factor graph:\n",
    "\n",
    "![factor1](imgs/factor2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_h1 = Distribution(np.array([[0.2], [0.8]]), ['h1'])\n",
    "p_h2_given_h1 = Distribution(np.array([[0.5, 0.2], [0.5, 0.8]]), ['h2', 'h1'])\n",
    "p_v1_given_h1 = Distribution(np.array([[0.6, 0.1], [0.4, 0.9]]), ['v1', 'h1'])\n",
    "p_v2_given_h2 = Distribution(p_v1_given_h1.probs, ['v2', 'h2'])\n",
    "\n",
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the marginal distribution $p(v_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23, 0.77])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})\n",
    "\n",
    "m = Messages()\n",
    "m.marginal(pgm.variable_from_name('v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('p(h1)', 'h1'): array([0.2, 0.8]),\n",
       " ('v1', 'p(v1|h1)'): 1.0,\n",
       " ('p(v1|h1)', 'h1'): array([1., 1.]),\n",
       " ('h1', 'p(h2|h1)'): array([0.2, 0.8]),\n",
       " ('p(h2|h1)', 'h2'): array([0.26, 0.74]),\n",
       " ('h2', 'p(v2|h2)'): array([0.26, 0.74]),\n",
       " ('p(v2|h2)', 'v2'): array([0.23, 0.77])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.marginal(pgm.variable_from_name('v1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "(From Bayesian Reasoning and Machine Learning, David Barber) You live in a house with three rooms, labelled 1, 2, 3. There is a door between rooms 1 and 2 and another between rooms 2 and 3. One cannot directly pass between rooms 1 and 3 in one time-step. An annoying fly is buzzing from one room to another and there is some smelly cheese in room 1 which seems to attract the fly more. Using $x_t$ for which room the fly is in at time t, with $dom(x_t) = {1,2,3}$, the movement of the fly can be described by a transition:\n",
    "$p(x_{t+1} = i|x_t = j) = M_{ij}$\n",
    "\n",
    "where M is a transition matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.5 & 0 \\\\\n",
    "0.3 & 0.3 & 0.5 \\\\\n",
    "0 & 0.2 & 0.5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Given that the fly is in room 1 at time 1, what is the probability of room occupancy at time t = 5? Assume a Markov chain which is defined by the joint distribution\n",
    "\n",
    "$p(x_1, . . . , x_T ) = p(x_1) \\prod p(x_{t+1}|x_t)$\n",
    "\n",
    "We are asked to compute $p(x_5|x_1 = 1)$ which is given by\n",
    "$\\sum p(x_5|x_4)p(x_4|x_3)p(x_3|x_2)p(x_2|x_1 = 1)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
